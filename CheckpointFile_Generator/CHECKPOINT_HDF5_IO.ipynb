{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a compatible GRChombo HDF5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains a template to generate a Checkpoint file for the ScalarField Example of GRChombo. In the following cell we create the variables for the file \n",
    "(e.g. a sinuisodial initial condition for the scalar field, while keeping the chi to one) \n",
    "\n",
    "The last cells automatically generates the HDF5 using h5py python library. \n",
    "\n",
    "WARNING: \n",
    "* I think when I created this template there were no output of GhostCells in the checkpoint files.  So, there could potentially be an issue there, if there has been any change there. \n",
    "* This template generates is only for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:04:08.366937Z",
     "start_time": "2019-06-12T13:04:08.167043Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checks\n",
      "K mean: -3.14\n",
      "phi mean: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "# import yt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "SET PARAMETERS\n",
    "\"\"\"\n",
    "path = \"/home/cjoana/GRChombo_outfiles/CHECKPOINT_HDF5_IO/\"\n",
    "filename = path +\"checkpoint_template.hdf5\"  # Name of the new file to create\n",
    "\n",
    "N = 32\n",
    "L = 128\n",
    "K_const = -3.14 # 4.68e-7\n",
    "dt_multiplier = 0.1\n",
    "\n",
    "def transform_PhiToChi(x): return np.exp(-2*x)\n",
    "\n",
    "# Set components\n",
    "component_names = [  # The order is important: component_0 ... component_(nth-1)\n",
    "    \"chi\",\n",
    "    \n",
    "    \"h11\",    \"h12\",    \"h13\",    \"h22\", \"h23\", \"h33\",\n",
    "\n",
    "    \"K\",\n",
    "\n",
    "    \"A11\",    \"A12\",    \"A13\",    \"A22\", \"A23\", \"A33\",\n",
    "\n",
    "    \"Theta\",\n",
    "\n",
    "    \"Gamma1\", \"Gamma2\", \"Gamma3\",\n",
    "\n",
    "    \"lapse\",\n",
    "\n",
    "    \"shift1\", \"shift2\", \"shift3\",\n",
    "\n",
    "    \"B1\",     \"B2\",     \"B3\",\n",
    "\n",
    "    \"phi\",    \"Pi\",\n",
    "\n",
    "    \"Ham\",    \"Mom1\",   \"Mom2\",   \"Mom3\"   \n",
    "]\n",
    "\n",
    "temp_comp = np.zeros((N, N, N))   # template for components: array [Nx, Ny. Nz]\n",
    "dset = dict()\n",
    "# Here set the value of the components (default: to zero)\n",
    "\n",
    "dset['chi'] = temp_comp.copy()\n",
    "dset['phi'] = temp_comp.copy()\n",
    "dset['K'] = temp_comp.copy() + K_const\n",
    "dset['Ham'] = temp_comp.copy()\n",
    "dset['h11'] = temp_comp.copy() + 1.\n",
    "dset['h22'] = temp_comp.copy() + 1.\n",
    "dset['h33'] = temp_comp.copy() + 1.\n",
    "dset['lapse'] = temp_comp.copy() + 1.\n",
    "\n",
    "\n",
    "## Constructing variables (example for SF)\n",
    "indices = []\n",
    "for z in range(N):\n",
    "    for y in range(N):\n",
    "        for x in range(N):\n",
    "            wvl = 2 * np.pi * 4 / L\n",
    "            ind = x + y*N + z*N**2 \n",
    "            dset['phi'][x][y][z] =  1 + 0.33 * np.sin(x * wvl) #+ np.sin(y * wvl) #+ np.sin(z* wvl)\n",
    "            dset['chi'][x][y][z] = 1. \n",
    "\n",
    "            indices.append(ind)\n",
    "            \n",
    "            \n",
    "## Constructing variables  (reading from file)  # Commented out as you don't have the files\n",
    "# sfdata = np.loadtxt(path + 'gridofsf,dat')\n",
    "# logconfdata = np.loadtxt(path + 'gridofphi.dat')\n",
    "# indices = []\n",
    "# for z in range(N):\n",
    "#     for y in range(N):\n",
    "#         for x in range(N):\n",
    "#             ind = x + y*N + z*N**2 \n",
    "#             dset['phi'][x][y][z] = sfdata[ind]\n",
    "#             dset['chi'][x][y][z] = transform_PhiToChi(logconfdata[ind]) \n",
    "#             indices.append(ind)\n",
    "\n",
    "print(\"checks\")\n",
    "print(\"K mean:\",  np.mean(dset['K']))\n",
    "print(\"phi mean:\",  np.mean( np.hstack(dset['phi'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:00:33.602284Z",
     "start_time": "2019-06-12T13:00:33.323102Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    print(\" ! > new mkdir: \", path)\n",
    "\n",
    "\"\"\"\n",
    "Mesh and Other Params\n",
    "\"\"\"\n",
    "# def base attributes\n",
    "base_attrb = dict()\n",
    "base_attrb['time'] = 0.0\n",
    "base_attrb['iteration'] = 0\n",
    "base_attrb['max_level'] = 0\n",
    "base_attrb['num_components'] = len(component_names)\n",
    "base_attrb['num_levels'] = 1\n",
    "base_attrb['regrid_interval_0'] = 1\n",
    "base_attrb['steps_since_regrid_0'] = 0\n",
    "for comp,  name in enumerate(component_names):\n",
    "    key = 'component_' + str(comp)\n",
    "    tt = 'S' + str(len(name))\n",
    "    base_attrb[key] = np.array(name, dtype=tt)\n",
    "\n",
    "\n",
    "# def Chombo_global attributes\n",
    "chombogloba_attrb = dict()\n",
    "chombogloba_attrb['testReal'] = 0.0\n",
    "chombogloba_attrb['SpaceDim'] = 3\n",
    "\n",
    "# def level0 attributes\n",
    "level_attrb = dict()\n",
    "level_attrb['dt'] = float(L)/N * dt_multiplier\n",
    "level_attrb['dx'] = float(L)/N\n",
    "level_attrb['time'] = 0.0\n",
    "level_attrb['is_periodic_0'] = 1\n",
    "level_attrb['is_periodic_1'] = 1\n",
    "level_attrb['is_periodic_2'] = 1\n",
    "level_attrb['ref_ratio']= 2\n",
    "level_attrb['tag_buffer_size'] = 3\n",
    "prob_dom = (0, 0, 0, N-1, N-1, N-1)\n",
    "prob_dt = np.dtype([('lo_i', '<i4'), ('lo_j', '<i4'), ('lo_k', '<i4'),\n",
    "                    ('hi_i', '<i4'), ('hi_j', '<i4'), ('hi_k', '<i4')])\n",
    "level_attrb['prob_domain'] = np.array(prob_dom, dtype=prob_dt)\n",
    "boxes = np.array([(0, 0, 0, N-1, N-1, N-1)],\n",
    "      dtype=[('lo_i', '<i4'), ('lo_j', '<i4'), ('lo_k', '<i4'), ('hi_i', '<i4'), ('hi_j', '<i4'), ('hi_k', '<i4')])\n",
    "\n",
    "\n",
    "\"\"\"\"\n",
    "CREATE HDF5\n",
    "\"\"\"\n",
    "\n",
    "#TODO: if overwrite:   [...] else: raise()\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "\n",
    "h5file = h5.File(filename, 'w')  # New hdf5 file I want to create\n",
    "\n",
    "# base attributes\n",
    "for key in base_attrb.keys():\n",
    "    h5file.attrs[key] = base_attrb[key]\n",
    "\n",
    "# group: Chombo_global\n",
    "chg = h5file.create_group('Chombo_global')\n",
    "for key in chombogloba_attrb.keys():\n",
    "    chg.attrs[key] = chombogloba_attrb[key]\n",
    "\n",
    "# group: levels\n",
    "l0 = h5file.create_group('level_0')\n",
    "for key in level_attrb.keys():\n",
    "    l0.attrs[key] = level_attrb[key]\n",
    "sl0 = l0.create_group('data_attributes')\n",
    "dadt = np.dtype([('intvecti', '<i4'), ('intvectj', '<i4'), ('intvectk', '<i4')])\n",
    "sl0.attrs['ghost'] = np.array((3, 3, 3),  dtype=dadt)\n",
    "sl0.attrs['outputGhost'] = np.array( (0, 0, 0),  dtype=dadt)\n",
    "sl0.attrs['comps'] = base_attrb['num_components']\n",
    "sl0.attrs['objectType'] = np.array('FArrayBox', dtype='S10')\n",
    "\n",
    "# level datasets\n",
    "dataset = np.zeros((base_attrb['num_components'], N, N, N))\n",
    "for i, comp in enumerate(component_names):\n",
    "    if comp in dset.keys():\n",
    "        dataset[i] = dset[comp].T\n",
    "fdset = []\n",
    "for c in range(base_attrb['num_components']):\n",
    "    fc = dataset[c].T.flatten()\n",
    "    fdset.extend(fc)\n",
    "fdset = np.array(fdset)\n",
    "\n",
    "l0.create_dataset(\"Processors\", data=np.array([0]))\n",
    "l0.create_dataset(\"boxes\",  data=boxes)\n",
    "l0.create_dataset(\"data:offsets=0\",  data=np.array([0, (base_attrb['num_components'])*N**3]))\n",
    "l0.create_dataset(\"data:datatype=0\",  data=fdset)\n",
    "\n",
    "h5file.close()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
